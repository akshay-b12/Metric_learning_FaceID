{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dml import LDML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import cv2\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "from skimage import data, feature, color, filters, img_as_float, io\n",
    "from matplotlib import pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 200)\n",
      "400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: overflow encountered in exp\n",
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log\n",
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.12149908e+05  1.17743564e+04  6.98746176e+03 ...  5.37471462e+02\n",
      "  -1.56717160e+02 -3.26558111e+02]\n",
      " [ 1.17743564e+04  1.74000053e+05 -3.56624566e+03 ...  9.11879705e-01\n",
      "  -2.62956096e+01 -2.55631444e+02]\n",
      " [ 6.98746176e+03 -3.56624566e+03  1.07644533e+05 ... -3.27642673e+02\n",
      "  -3.39858572e+01 -7.91748467e+00]\n",
      " ...\n",
      " [ 5.37471462e+02  9.11879705e-01 -3.27642673e+02 ...  2.78043755e+02\n",
      "  -1.86213974e+01 -2.72035076e+00]\n",
      " [-1.56717160e+02 -2.62956096e+01 -3.39858572e+01 ... -1.86213974e+01\n",
      "   2.87008309e+02 -3.96151078e-01]\n",
      " [-3.26558111e+02 -2.55631444e+02 -7.91748467e+00 ... -2.72035076e+00\n",
      "  -3.96151078e-01  2.59808388e+02]]\n",
      "LDML accuracy on test set of 200 points: 0.6833\n"
     ]
    }
   ],
   "source": [
    "# Load a data set\n",
    "bunch = fetch_olivetti_faces()\n",
    "#print(type(bunch.data))\n",
    "\n",
    "pca = PCA(n_components=200)\n",
    "output_pca = pca.fit_transform(bunch.data)\n",
    "print(output_pca.shape)\n",
    "print(len(bunch.data))\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "for sample in range(len(bunch.data)):\n",
    "    if sample%10 < 7:\n",
    "        X_train.append(output_pca[sample])\n",
    "        y_train.append(bunch.target[sample])\n",
    "    else :\n",
    "        X_test.append(output_pca[sample])\n",
    "        y_test.append(bunch.target[sample])\n",
    "        \n",
    "ldml_instance = LDML()\n",
    "#print(ldml_instance.get_params())\n",
    "#X_train = np.asarray(X_train)\n",
    "#y_train = np.asarray(y_train)\n",
    "ldml_instance.fit(np.asarray(X_train), np.asarray(y_train))\n",
    "print(ldml_instance.metric())\n",
    "\n",
    "k_test = 3\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=k_test)\n",
    "knn.fit(ldml_instance.transform(X_train), y_train)\n",
    "\n",
    "# Compute the k-nearest neighbor test accuracy after applying the learned transformation\n",
    "ldml_acc = knn.score(ldml_instance.transform(X_test), y_test)\n",
    "print('LDML accuracy on test set of {} points: {:.4f}'.format(len(X_test[0]), ldml_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "def landkark_detector(img):\n",
    "    # load the input image, resize it, and convert it to grayscale\n",
    "    image = cv2.imread(\"example_01.jpg\")\n",
    "    #image = imutils.resize(image, width=500)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # detect faces in the grayscale image\n",
    "    rects = detector(gray, 1)\n",
    "    \n",
    "    # loop over the face detections\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "        # array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "    \n",
    "        # convert dlib's rectangle to a OpenCV-style bounding box\n",
    "        # [i.e., (x, y, w, h)], then draw the face bounding box\n",
    "        (x, y, w, h) = face_utils.rect_to_bb(rect)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(image, (x, y), 1, (0, 0, 255), -1)\n",
    "    cv2.imshow(\"Output\", image)\n",
    "    \n",
    "    \n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6\n",
      "2.2627416997969525\n",
      "3.200000000000001\n"
     ]
    }
   ],
   "source": [
    "def get_sift_descriptors(gray, keypoints):\n",
    "    kp,des = sift.compute(gray,kp)\n",
    "    img=cv2.drawKeypoints(gray,kp,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    cv2.imwrite('sift_keypoints.jpg',img)\n",
    "    return kp, des\n",
    "\n",
    "# load the input image, resize it, and convert it to grayscale\n",
    "image = cv2.imread(\"example_01.jpg\")\n",
    "#image = imutils.resize(image, width=500)\n",
    "img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#original_image = io.imread(\"example_01.jpg\")\n",
    "#img = color.rgb2gray(original_image)\n",
    "\n",
    "k = math.sqrt(2)\n",
    "sigma = 1.6\n",
    "#plt.subplot(2,3,1)\n",
    "#plt.imshow(original_image)\n",
    "#plt.title('Original Image')\n",
    "\n",
    "for idx in range(0,3):\n",
    "    #s1 = filters.gaussian(img,(k**idx)*sigma)\n",
    "    blur = cv2.GaussianBlur(img,(3,3),(k**idx)*sigma)\n",
    "    print((k**idx)*sigma)\n",
    "    #print(s1.dtype)\n",
    "    #s2 = filters.gaussian(img,(k**(idx-1))*sigma)\n",
    "    #io.imsave(\"img\"+str(idx)+\".jpg\",s1)\n",
    "    # multiply by sigma to get scale invariance\n",
    "    #dog = s1 - s2\n",
    "    #plt.subplot(3,3,idx+2)\n",
    "    #print (dog.min(),dog.max())\n",
    "    #plt.imshow(s1)\n",
    "    cv2.imshow(\"gauss\",blur)\n",
    "    cv2.imwrite(\"img\"+str(idx)+\".jpg\", blur)\n",
    "    #plt.title('DoG with sigma=' + str(sigma) + ', k=' + str(k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
